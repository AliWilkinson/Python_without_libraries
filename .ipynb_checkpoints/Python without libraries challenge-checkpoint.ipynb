{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd79d98a",
   "metadata": {},
   "source": [
    "# Python Programming without using Libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1a8cf9",
   "metadata": {},
   "source": [
    "### Develop a function to find the geometric mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a80aa8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.40574036744275"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_geometric_mean(nums_list):\n",
    "    '''calculate the geometric mean for a list'''\n",
    "    product = 1\n",
    "    for x in nums_list:\n",
    "        product *= x\n",
    "    root = len(nums_list)\n",
    "    gm = pow(product, 1/root)\n",
    "    return gm\n",
    "\n",
    "\n",
    "numbers = [64, 9, 90, 28, 46, 95, 34, 28, 86, 62, 14, 77, 99, 80, 99, 56, 79, 37, 74, 6, 67, 32, 5, 94, 53, 62, 19, 44, 16, 74, 92, 60, 74, 80, 10, 43, 51, 41, 91, 41, 27, 40, 48, 27, 13, 41, 13, 28, 17, 64]        \n",
    "find_geometric_mean(numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5602dc",
   "metadata": {},
   "source": [
    "###  Develop a function to read a single column from a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5cd88ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_column(data_file, column_no, conversion_indicator):\n",
    "    '''read a column from a csv file'''\n",
    "    with open(data_file, 'r') as csv_file:\n",
    "        lines = csv_file.readlines()\n",
    "        columns = lines[0].strip('\\n').split(',')\n",
    "        column_name = columns[column_no]\n",
    "        line = lines[1:]\n",
    "        data = [row.strip('\\n').split(',') for row in line]\n",
    "        column_data = []\n",
    "        # if the conversion_indicator is True, convert the value to a float\n",
    "        for row in data:\n",
    "            if conversion_indicator == True:\n",
    "                column_data.append(float(row[column_no]))\n",
    "            else:\n",
    "                column_data.append(row[column_no])\n",
    "        \n",
    "    return column_name, column_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing function        \n",
    "read_column('task1.csv', 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cf3bdd",
   "metadata": {},
   "source": [
    "### Develop a function to read CSV data from a file into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fcb5bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_dictionary(data_file, ci_list):\n",
    "    data_dict = {}\n",
    "    with open(data_file, 'r') as csv_file:\n",
    "        lines = csv_file.readlines()\n",
    "        columns = lines[0].strip('\\n').split(',')\n",
    "    \n",
    "    for i in range(0, len(columns)):\n",
    "        col_data = read_column('task1.csv', i, ci_list[i])\n",
    "        data_dict[col_data[0]] = col_data[1]\n",
    "    \n",
    "    return data_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c57bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "test_ci = [True, False, False, False, True, False, True, True, False, True]\n",
    "create_data_dictionary('task1.csv', test_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd75e76",
   "metadata": {},
   "source": [
    "### Develop a function to calculate the Spearman’s Rank Correlation Coefficient for two named columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1812031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to rank the values in a list\n",
    "\n",
    "# FOR EACH EQUAL RANK - ADD THEM UP AND DIVIDE BY THE COUNT OF THE EQUAL RANK \n",
    "# REPLACE THE EQUAL RANKS WITH THE NEW VALUE\n",
    "\n",
    "def rank_values(column):\n",
    "    '''Takes a column of a dataset and ranks the values in the column. For tied ranks - adds up the ranks and divides \n",
    "    by the number of ties'''\n",
    "    sorted_column = sorted(column, reverse=True)\n",
    "    col_ranks = [sorted_column.index(y) + 1 for y in column]\n",
    "    new_ranks = [sorted_column.index(y) + 1 for y in column]\n",
    "\n",
    "\n",
    "    enum_col_ranks = list(enumerate(col_ranks))\n",
    "    dups = []\n",
    "    for r in col_ranks:\n",
    "        # check if r is duplicated in the list of ranks and if the new rank has previously been calculated (r is in the dups list)\n",
    "        if r not in dups and col_ranks.count(r) > 1:\n",
    "            count = col_ranks.count(r)\n",
    "            #print(count)\n",
    "            r_list = []\n",
    "            # add the rank to r_list for how many times r appears in the original data\n",
    "            for i in range(0, count):\n",
    "                r_list.append(r)\n",
    "            #print(r_list)\n",
    "            # add an extra 1 to each subsequent count of r\n",
    "            for i in range(0, count):\n",
    "                r_list[i] += i         \n",
    "            #print(r_list)\n",
    "            sum = 0\n",
    "            # add up the ranks \n",
    "            for rank in r_list:\n",
    "                sum += rank\n",
    "            #print(sum)\n",
    "            # divide the sum of the rakls by how many counts of r there are \n",
    "            new_rank = sum / len(r_list)\n",
    "            #print(new_rank)\n",
    "            \n",
    "            # for each value of r, replace the orginal rank with the new calculated rank (new_rank)\n",
    "            for er in enum_col_ranks:\n",
    "                if r == er[1]:\n",
    "                    new_ranks[er[0]] = new_rank\n",
    "            # add the values that are duplicated in the original data to the dups list         \n",
    "            dups.append(r)\n",
    "            \n",
    "            # return the list of the ranks with the calculated ranks for values that appear more than once \n",
    "    return new_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d121c838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008026176175249066\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def arithmetic_mean(a_list):\n",
    "    '''function to find arithmetic mean \n",
    "    '''\n",
    "    total = 0\n",
    "    for a in a_list:\n",
    "        total += a\n",
    "    a_mean = total / len(a_list)\n",
    "    return a_mean\n",
    "\n",
    "\n",
    "\n",
    "def spearmans_cor(col1, col2):\n",
    "    ''' function to calculate spearmans rank correlation coefficient - uses rank_values and arithmetic_mean functions'''\n",
    "    # check the two columns given are the same length\n",
    "    if len(col1) == len(col2):\n",
    "         \n",
    "       # call function to rank the columns\n",
    "        col1_ranks = rank_values(col1)\n",
    "        col2_ranks = rank_values(col2)\n",
    "        \n",
    "        n = len(col1)\n",
    "        \n",
    "        # call function to calculate the arithmetic mean of the \n",
    "        mean_x = arithmetic_mean(col1_ranks)\n",
    "        mean_y = arithmetic_mean(col2_ranks)\n",
    "        \n",
    "       \n",
    "        # calculate the correlation coefficient from the ranked columns and the means  \n",
    "        covariance = 0\n",
    "        Sxx = 0\n",
    "        Syy = 0\n",
    "        length = len(col1_ranks)\n",
    "        for i in range(0, length):\n",
    "            a = (col1_ranks[i] - mean_x) * (col2_ranks[i] - mean_y)\n",
    "            var_x = (col1_ranks[i] - mean_x)**2\n",
    "            var_y = (col2_ranks[i] - mean_y)**2\n",
    "            covariance += a\n",
    "            Sxx += var_x\n",
    "            Syy += var_y\n",
    "    \n",
    "        deviation = pow((Sxx/n) * (Syy/n), 1/2)\n",
    "        Sxy = covariance / n\n",
    "        \n",
    "        s_rank_cc = Sxy / deviation\n",
    "        return s_rank_cc\n",
    "    else:\n",
    "        print('Columns need to be the same length')\n",
    "    \n",
    "\n",
    "# list of conversion indicators to convert all data to floats\n",
    "tt = [True, True, True,True,True,True,True,True,True,True] \n",
    "dd = create_data_dictionary('task1.csv', tt)\n",
    "\n",
    "# test function            \n",
    "print(spearmans_cor(dd['age'], dd['pop']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d72a39c",
   "metadata": {},
   "source": [
    "### Develop a function to generate a set of Spearman’s Rank Correlation Coefficients for a given data file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80605caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'pop', 0.008026176175249066),\n",
       " ('age', 'share_white', 0.2204529612673686),\n",
       " ('age', 'share_black', -0.10391191654459546),\n",
       " ('age', 'share_hispanic', -0.1492393985153156),\n",
       " ('age', 'personal_income', 0.06107877804805902),\n",
       " ('age', 'household_income', 0.06388015417505191),\n",
       " ('age', 'poverty_rate', -0.12184277407334046),\n",
       " ('age', 'unemployment_rate', -0.09655098862145423),\n",
       " ('age', 'uni_education_25+', 0.028208882767439082),\n",
       " ('pop', 'age', 0.008026176175249066),\n",
       " ('pop', 'share_white', 0.07665075056965713),\n",
       " ('pop', 'share_black', -0.13404143894448056),\n",
       " ('pop', 'share_hispanic', 0.127773940051733),\n",
       " ('pop', 'personal_income', 0.22095954372586357),\n",
       " ('pop', 'household_income', 0.3136941696064098),\n",
       " ('pop', 'poverty_rate', -0.28696748318702975),\n",
       " ('pop', 'unemployment_rate', -0.15865388884674456),\n",
       " ('pop', 'uni_education_25+', 0.12468510402281516),\n",
       " ('share_white', 'age', 0.2204529612673686),\n",
       " ('share_white', 'pop', 0.07665075056965713),\n",
       " ('share_white', 'share_black', -0.4918877267785082),\n",
       " ('share_white', 'share_hispanic', -0.5205090931830775),\n",
       " ('share_white', 'personal_income', 0.405397927209652),\n",
       " ('share_white', 'household_income', 0.3733538262802457),\n",
       " ('share_white', 'poverty_rate', -0.47757482465482576),\n",
       " ('share_white', 'unemployment_rate', -0.38147433562674116),\n",
       " ('share_white', 'uni_education_25+', 0.36226504531686904),\n",
       " ('share_black', 'age', -0.10391191654459546),\n",
       " ('share_black', 'pop', -0.13404143894448056),\n",
       " ('share_black', 'share_white', -0.4918877267785082),\n",
       " ('share_black', 'share_hispanic', -0.17363748079358468),\n",
       " ('share_black', 'personal_income', -0.2558605567002337),\n",
       " ('share_black', 'household_income', -0.3601118810277946),\n",
       " ('share_black', 'poverty_rate', 0.3432341973963418),\n",
       " ('share_black', 'unemployment_rate', 0.3365985336319584),\n",
       " ('share_black', 'uni_education_25+', -0.11804019213206135),\n",
       " ('share_hispanic', 'age', -0.1492393985153156),\n",
       " ('share_hispanic', 'pop', 0.127773940051733),\n",
       " ('share_hispanic', 'share_white', -0.5205090931830775),\n",
       " ('share_hispanic', 'share_black', -0.17363748079358468),\n",
       " ('share_hispanic', 'personal_income', -0.1261675240998713),\n",
       " ('share_hispanic', 'household_income', -0.022932298578312818),\n",
       " ('share_hispanic', 'poverty_rate', 0.1634674619726741),\n",
       " ('share_hispanic', 'unemployment_rate', 0.04984391016479382),\n",
       " ('share_hispanic', 'uni_education_25+', -0.17823310401609602),\n",
       " ('personal_income', 'age', 0.06107877804805902),\n",
       " ('personal_income', 'pop', 0.22095954372586357),\n",
       " ('personal_income', 'share_white', 0.405397927209652),\n",
       " ('personal_income', 'share_black', -0.2558605567002337),\n",
       " ('personal_income', 'share_hispanic', -0.1261675240998713),\n",
       " ('personal_income', 'household_income', 0.8582991099150271),\n",
       " ('personal_income', 'poverty_rate', -0.816206632582188),\n",
       " ('personal_income', 'unemployment_rate', -0.5440057499075077),\n",
       " ('personal_income', 'uni_education_25+', 0.6920088727699469),\n",
       " ('household_income', 'age', 0.06388015417505191),\n",
       " ('household_income', 'pop', 0.3136941696064098),\n",
       " ('household_income', 'share_white', 0.3733538262802457),\n",
       " ('household_income', 'share_black', -0.3601118810277946),\n",
       " ('household_income', 'share_hispanic', -0.022932298578312818),\n",
       " ('household_income', 'personal_income', 0.8582991099150271),\n",
       " ('household_income', 'poverty_rate', -0.8737298288578947),\n",
       " ('household_income', 'unemployment_rate', -0.5471240911352426),\n",
       " ('household_income', 'uni_education_25+', 0.6216763133840255),\n",
       " ('poverty_rate', 'age', -0.12184277407334046),\n",
       " ('poverty_rate', 'pop', -0.28696748318702975),\n",
       " ('poverty_rate', 'share_white', -0.47757482465482576),\n",
       " ('poverty_rate', 'share_black', 0.3432341973963418),\n",
       " ('poverty_rate', 'share_hispanic', 0.1634674619726741),\n",
       " ('poverty_rate', 'personal_income', -0.816206632582188),\n",
       " ('poverty_rate', 'household_income', -0.8737298288578947),\n",
       " ('poverty_rate', 'unemployment_rate', 0.5513922054073722),\n",
       " ('poverty_rate', 'uni_education_25+', -0.5824228624797371),\n",
       " ('unemployment_rate', 'age', -0.09655098862145423),\n",
       " ('unemployment_rate', 'pop', -0.15865388884674456),\n",
       " ('unemployment_rate', 'share_white', -0.38147433562674116),\n",
       " ('unemployment_rate', 'share_black', 0.3365985336319584),\n",
       " ('unemployment_rate', 'share_hispanic', 0.04984391016479382),\n",
       " ('unemployment_rate', 'personal_income', -0.5440057499075077),\n",
       " ('unemployment_rate', 'household_income', -0.5471240911352426),\n",
       " ('unemployment_rate', 'poverty_rate', 0.5513922054073722),\n",
       " ('unemployment_rate', 'uni_education_25+', -0.5366906710536492),\n",
       " ('uni_education_25+', 'age', 0.028208882767439082),\n",
       " ('uni_education_25+', 'pop', 0.12468510402281516),\n",
       " ('uni_education_25+', 'share_white', 0.36226504531686904),\n",
       " ('uni_education_25+', 'share_black', -0.11804019213206135),\n",
       " ('uni_education_25+', 'share_hispanic', -0.17823310401609602),\n",
       " ('uni_education_25+', 'personal_income', 0.6920088727699469),\n",
       " ('uni_education_25+', 'household_income', 0.6216763133840255),\n",
       " ('uni_education_25+', 'poverty_rate', -0.5824228624797371),\n",
       " ('uni_education_25+', 'unemployment_rate', -0.5366906710536492)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spearmans_rank_for_columns(data_file, ci_list):\n",
    "    '''for a data file, take each column and calculate the srcc compared to all other columns'''\n",
    "    data_dict = create_data_dictionary(data_file, ci_list)\n",
    "    \n",
    "    # compare each column to the other columns, save as tuples and add to list\n",
    "    # nested loop to compaire each column to the others\n",
    "    \n",
    "    column_pairs = []\n",
    "    for key, value in data_dict.items():\n",
    "        for key1, value1 in data_dict.items():\n",
    "            # value_pairs = (value, value1)\n",
    "            if key != key1:\n",
    "                srcc = spearmans_cor(value, value1)\n",
    "                pairs_coef_tups = (key, key1, srcc)\n",
    "                column_pairs.append(pairs_coef_tups)\n",
    "   \n",
    "    return column_pairs\n",
    "    \n",
    "\n",
    "\n",
    "conf_int_list = [True, True, True,True,True,True,True,True,True,True]    \n",
    "spearmans_rank_for_columns('task1.csv', conf_int_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196310ba",
   "metadata": {},
   "source": [
    "### Develop a function to print a custom table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cd67d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "                    *       age        *       pop        *   share_black    *   share_white    *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "*        age        *        -         *      0.008       *     -0.1039      *      0.2205      *\n",
      "*        pop        *      0.008       *        -         *      -0.134      *      0.0767      *\n",
      "*    share_black    *     -0.1039      *      -0.134      *        -         *     -0.4919      *\n",
      "*    share_white    *      0.2205      *      0.0767      *     -0.4919      *        -         *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "def srcc_table(tuples_list, bc, column_names):\n",
    "    '''Makes sure four columns are given and that these columns are unique. Takes the Spearmans correlations for the columns\n",
    "    given and returns a table showing the SC between each column listed'''\n",
    "    \n",
    "    # need 4 columns for the table to work correctly\n",
    "    if len(column_names) != 4:\n",
    "        print('Please give 4 columns')    \n",
    "    \n",
    "    else:\n",
    "        # makes sure each column name is unique\n",
    "        col_set = set(column_names)\n",
    "        if len(col_set) != 4:\n",
    "            print('Please give 4 unique column names')\n",
    "        else: \n",
    "        \n",
    "            # sort column names\n",
    "            column_names = sorted(column_names)\n",
    "\n",
    "            srcc_list = []\n",
    "            \n",
    "            # add the tuples that are in the list of columns to the srcc_list\n",
    "            for tup in tuples_list:\n",
    "                if tup[0] in column_names and tup[1] in column_names:\n",
    "                    srcc_list.append(tup)\n",
    "\n",
    "            #sort tuples\n",
    "            srcc_list = sorted(srcc_list)\n",
    "\n",
    "            # table \n",
    "            print('{:^20}'.format(''), bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc)\n",
    "            print('{:^20}{}{:^18}{}{:^18}{}{:^18}{}{:^18}{}'.format('', bc, column_names[0], bc, column_names[1], bc, column_names[2], bc, column_names[3], bc))\n",
    "            print(bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc)\n",
    "            print('{}{:^19}{}{:^18}{}{:^18}{}{:^18}{}{:^18}{}'.format(bc, column_names[0], bc, '-', bc, round(srcc_list[0][2], 4), bc, round(srcc_list[1][2], 4), bc, round(srcc_list[2][2], 4), bc))\n",
    "            print('{}{:^19}{}{:^18}{}{:^18}{}{:^18}{}{:^18}{}'.format(bc, column_names[1], bc, round(srcc_list[3][2], 4), bc, '-', bc, round(srcc_list[4][2], 4), bc, round(srcc_list[5][2], 4), bc))\n",
    "            print('{}{:^19}{}{:^18}{}{:^18}{}{:^18}{}{:^18}{}'.format(bc, column_names[2], bc, round(srcc_list[6][2], 4), bc, round(srcc_list[7][2], 4), bc, '-', bc, round(srcc_list[8][2], 4), bc))\n",
    "            print('{}{:^19}{}{:^18}{}{:^18}{}{:^18}{}{:^18}{}'.format(bc, column_names[3], bc, round(srcc_list[9][2], 4), bc, round(srcc_list[10][2], 4), bc, round(srcc_list[11][2], 4), bc, '-', bc))\n",
    "            print(bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc, bc)\n",
    "    \n",
    "    \n",
    "# calculate correlations for the columns in the dataset    \n",
    "srcc_tuples = spearmans_rank_for_columns('task1.csv', conf_int_list)\n",
    "# list desired columns \n",
    "columns = ['age', 'pop', 'share_black', 'share_white']\n",
    "\n",
    "srcc_table(srcc_tuples, '*', columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6604cd98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
